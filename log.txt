
*****
3-11-23
Added check for Inf. Needed to change starting point for components without lower or upper bounds.
Added 1+ in denominator of primal and dual feasibility. This avoid issues with zero obj or rhs.
Added calculation of dual objective function and potential stopping criterion based on scaled duality gap. It looks like sometimes it may not work properly. Modified screen output accordingly.
Moved some parameters to IPM_const.h. It's easier to control the algorithm.
Moved getNonzeros after permutation is finished, so that it uses the fictitious matrix A with all entries set to one. This avoids that certain nonzeros are ignore because too small during the call to computeAThetaAT.
---
stat96v2.mps shows strange behaviour. Stepsizes go to zero and algorithm stagnates. Before that, primal infeas grows with stepwise 0.99. Need to check the residuals of the linear system to see if direction is accurate. 
---
Computation of Schur complement remains slow. Major contribution is the forward solve with all the columns. Need to solve all the columns at once, rather than one at a time. May bring small advantage. For neos-5052403-cygnet.mps, we are competitive with ipx, without parallelization implemented.
---

*****
6-11-23
Added computation of the residuals of the linear system. They appear low for all problems, including stat96v2.mps, but I don't know if they are low enough. It's difficult to obtain a relative measure, because the corresponding res_j may be very close to zero. Absolute values of infinity norms of the differences are of the order 1e-4 or lower. Maybe this is not low enough and needs some refinement after the solve. 
---
For neos-5052403-cygnet.mps with normal equations, most of the time is taken by building the normal equations at each iteration, because the Schur complement has size zero. Using Metis with normal equations corresponds to slicing matrix A into blocks of rows:

     [ A1 ]                                       [ A1*A1^T   0     A1*A3^T ]
 A = [ A2 ]    A^T = [ A1^T A2^T A3^T]    A*A^T = [   0     A2*A2^T A2*A3^T ]
     [ A3 ]                                       [ A3*A1^T A3*A2^T A3*A3^T ]

such that A1*A2^T is the zero matrix. Rather than computing A*A^T every time, I can compute all the five (or 2*nparts+1) nonzero blocks of A*A^T in parallel, using the previously stored slices of rows of A and the new Theta vector.
This requires storing the slices row and column wise. Also, computing Aj*Aj^T exploits symmetry, but computing Ai*Aj^T does not. Is this an issue?
---
Implemented forward/diagonal solve for all columns at once. It bring substantial benefit. E.g.
25fv47 with normal equations :  0.65 -> 0.23
25fv47 with augmented system :  2.66 -> 0.68 
80bau3b with normal equations:  1.80 -> 1.04
80bau3b with augmented system: 12.56 -> 4.09
Need to understand exactly how solving all rhs together brings such large benefit, to implement it later on in our factorisation.
Added warning that debug is on for large problems, as it was hampering performance before I noticed.
---
Need to add LU factorisation from HFactor. Need to create function, to be called from Metis_caller::factor(), that computes contribution to the Schur complement for a given linking and diagonal block, to improve modularity. Then, Metis_caller::factor() does not have to change, and I can add any method to compute the contribution to the Schur complement.
---


*****
7-11-23
Factorization of the schur complement switched to dense Lapack routine, using dsytrf and dsytrs. 
Avoid converting schur complement from dense to spase and using inefficient sparse factorization for it.
---
Added checks for empty schur complement, otherwise lapack complains.
Separated computation of contributions to schur complement from Metis_caller::factor(). Now they are in a separate file and one can add any method he wants.
Added HFactor as general solver (not for metis yet). It seems to be considerably slower than MA86. Julian's experiments seemed to indicate the opposite, not sure what is happening here. Also, it fails in a weird way for 80bau3b with augmented system.
---
It looks like MA86 does not produce an elimination ordering. That's weird because the code is quite performant. Checking the number of nonzero in the computed factor and comparing with the factor that Matlab produces, it looks like indeed there is large margin of improvement. 
I need to use HSL_MC68 to produce a good elimination ordering to pass to MA86. I hope it works without using Metis, otherwise I need to switch to the old Metis 4 and change the interface.
---


*****
8-11-23
Inserted MC68 to compute the elimination ordering. It reduces the number of nonzeros in the L factor considerably (5 times for 80bau3b). Times improve considerably.
For neos-5052403-cygnet the effect is much smaller.
---
Extra experiments using HFactor. 
For 80bau3b, L from MA86 has 107k entries, L and U together from HFactor have 75k entries. 
Solve time is slightly reduced due to this. However, factorization time is much larger (0.05 vs 0.75).
For neos-5052403-cygnet, starting point not yet computed after 5 minutes. MA86 converges in 15s.
For stat96v2, L from MA86 has 1.7M entries, LU from HFactor have 4.2M entries. Factorization is much slower.
---
Need to run the code on the whole Netlib collection. Maybe compare times of MA86 and HFactor. 
Need a master file to run all problems.


*****
9-11-23
Computed netlib results for various combinations of type of linear system, regularization and tolerance. 
Normal equations is usually faster, but fails to converge for come problems. Augmented system without regularization converges for all 96 problems.
Regularization seems to only make things worse. Need specialized dynamic regularization within the factorization.
Added extraction of problem name from path. Added print of problem name to screen.
---


*****
10-11-23
Managed to make solution with Metis blocks work with HFactor. Needed to use the correct permutation at the correct point in the code. 
Needed also to make ftranL and btranU public in HFactor.h.
I still need to make extensive tests, but it looks like for some problems it brings some benefit. 
However, for other problems it is incredibly slow and sometimes it just fails. It goes well until at some point the direction is not correct anymore and the iterations start diverging. Weird.
I don't understand why sometimes the starting point alone takes a lot of time. Need to switch the starting point to use metis blocks as well.
---
For next week, I need to understand how to make the code parallel and do some more tests to check when HFactor is better.


*****
13-11-23
Changed starting point to use metis blocks. 
When using normal equations, minimal changes needed. 
When using augmented system, solution of A*A^T * q = s + A*r is found by solving
    [ -I  A^T] [ p ] = [ r ]
    [  A   0 ] [ q ] = [ s ]
and ignoring the solution p. I changed this also for the non-metis augmented system, to avoid forming A*A^T (it may be much denser).
---
Added break in main loop is an error occurs during factorization (any type, normal equation, augmented, metis or not). 
Weird behaviour for some problems seems to be caused by error in factorization. Incomplete of wrong data is used to solve the following linear systems.